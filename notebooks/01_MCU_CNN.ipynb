{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model on a MCU NN Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch2cmsis.converter import CMSISConverter\n",
    "\n",
    "from nn_deployment_course.mcu.utils import transform_cifar10, sample_from_class, SimpleTrainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "First, we load the dataset and split it in training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = CIFAR10(\n",
    "    root=\"./data/data_cifar10/\",\n",
    "    train=True,\n",
    "    transform=transform_cifar10(),\n",
    "    download=True\n",
    "    )\n",
    "val_set, tr_set = sample_from_class(train_set, 500)\n",
    "test_set = CIFAR10(\n",
    "    root=\"./data/data_cifar10/\",\n",
    "    train=False,\n",
    "    transform=transform_cifar10(),\n",
    "    download=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can build the dataloaders with batch size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "datasets = [tr_set, val_set, test_set]\n",
    "dataloaders = {\n",
    "    i: DataLoader(\n",
    "        sett, batch_size=8, shuffle=True, num_workers=4\n",
    "    )\n",
    "    for i, sett in zip([\"train\", \"val\", \"test\"], datasets)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleCNN(nn.Module):\n",
    "    def __init__(self, shape=(3, 32, 32), batch_size=4):\n",
    "        super().__init__()\n",
    "        self.input_shape = shape\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=shape[0], out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3)\n",
    "        self.pool2 = nn.AvgPool2d(2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3)\n",
    "        self.pool3 = nn.AvgPool2d(2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.interface_shape = self.get_shape()\n",
    "        self.interface = nn.Linear(in_features=self.interface_shape.numel(), out_features=10)\n",
    "\n",
    "    def get_shape(self):\n",
    "        sample = torch.randn(size=(self.batch_size, *self.input_shape)).type_as(self.conv1.weight)\n",
    "        out = self.conv1(sample)\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = self.relu3(out)\n",
    "        return out.shape[1:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.flatten(out)\n",
    "        return self.interface(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's declare the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3, 32, 32)\n",
    "cnn = SampleCNN(shape=input_shape, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Let's train, but before let's declare the trainer and the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SimpleTrainer(datasets=datasets, dataloaders=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_step\": 5000,\n",
    "    \"learning_gamma\": 0.99,\n",
    "    \"epochs\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.558: 100%|██████████| 2/2 [00:31<00:00, 15.72s/it]\n"
     ]
    }
   ],
   "source": [
    "cnn = trainer.train(cnn, hyperparam, \"cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set now the network to evaluation mode and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "accuracy_test = trainer.evaluate(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test set with PyTorch  0.561\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for test set with PyTorch \", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COnvert to CMSIS-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert it to CMSIS with the CMSIS converter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_config = {\n",
    "    \"compilation\": \"gcc -g -I../../../CMSIS_5/CMSIS/Core/Include \\\n",
    "            -I../../../CMSIS_5/CMSIS/DSP/Include \\\n",
    "            -I../../../CMSIS_5/CMSIS/NN/Include \\\n",
    "            -D__ARM_ARCH_8M_BASE__ \\\n",
    "            ../../../CMSIS_5/CMSIS/NN/Source/*/*.c \\\n",
    "            ../../../CMSIS_5/CMSIS/DSP/Source/StatisticsFunctions/arm_max_q7.c \\\n",
    "            main.c -o main\",\n",
    "    \"exec_path\": \"main\",\n",
    "        }\n",
    "os.makedirs(\"cfiles\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(torch2cmsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_converter = CMSISConverter(\n",
    "    root=\"cfiles\",\n",
    "    model=cnn,\n",
    "    weight_file_name=\"weights.h\",\n",
    "    parameter_file_name=\"parameters.h\",\n",
    "    weight_bits=8,\n",
    "    compilation=conversion_config.get(\"compilation\"),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining .weight: 100%|██████████| 4/4 [00:00<00:00, 2706.00it/s]\n",
      "Refining .bias: 100%|██████████| 4/4 [00:00<00:00, 2602.33it/s]\n",
      "Refining activations: 100%|██████████| 4/4 [00:19<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "cm_converter.convert_model(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gcc: error: ../CMSIS_5/CMSIS/NN/Source/*/*.c: No such file or directory\n",
      "gcc: error: ../CMSIS_5/CMSIS/DSP/Source/StatisticsFunctions/arm_max_q7.c: No such file or directory\n",
      "gcc: error: main.c: No such file or directory\n",
      "gcc: fatal error: no input files\n",
      "compilation terminated.\n",
      "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cm_converter\u001b[39m.\u001b[39;49mevaluate_cmsis(conversion_config\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mexec_path\u001b[39;49m\u001b[39m\"\u001b[39;49m), dataloaders[\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/course/lib/python3.8/site-packages/torch2cmsis/converter.py:423\u001b[0m, in \u001b[0;36mCMSISConverter.evaluate_cmsis\u001b[0;34m(self, exec_path, loader)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mfor\u001b[39;00m inp, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(input_batch, label_batch):\n\u001b[1;32m    422\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantize_input(inp)\n\u001b[0;32m--> 423\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(exec_path)\n\u001b[1;32m    424\u001b[0m     pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(out)\n\u001b[1;32m    425\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred \u001b[39m==\u001b[39m label\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/course/lib/python3.8/site-packages/torch2cmsis/converter.py:412\u001b[0m, in \u001b[0;36mCMSISConverter.execute\u001b[0;34m(self, exec_path)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, exec_path):\n\u001b[0;32m--> 412\u001b[0m     call(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m\"\u001b[39;49m, exec_path), cwd\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m    413\u001b[0m     \u001b[39m# TODO: this implies that the executable produces this file\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mfromfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio_folder, \u001b[39m\"\u001b[39m\u001b[39my_out.raw\u001b[39m\u001b[39m\"\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint8)\n",
      "File \u001b[0;32m~/miniconda3/envs/course/lib/python3.8/subprocess.py:340\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39m*\u001b[39mpopenargs, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m     \u001b[39m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m    341\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m             \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/course/lib/python3.8/subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    856\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 858\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    859\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    860\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    861\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    862\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    863\u001b[0m                         errread, errwrite,\n\u001b[1;32m    864\u001b[0m                         restore_signals, start_new_session)\n\u001b[1;32m    865\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    867\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/miniconda3/envs/course/lib/python3.8/subprocess.py:1704\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1703\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1704\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1705\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './main'"
     ]
    }
   ],
   "source": [
    "cm_converter.evaluate_cmsis(conversion_config.get(\"exec_path\"), dataloaders[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = next(iter(dataloaders[\"test\"]))\n",
    "cm_converter.sample_inference_checker(conversion_config.get(\"exec_path\"), input, draw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03295f4516bf5577f413a125e84959d67a4ab4350b23f979a91ef1ccf1ee10d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
