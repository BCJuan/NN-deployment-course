{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation on Embedded GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BronchoTrack.BronchoTrack.models.offsetnet import OffsetNet\n",
    "from torch import onnx as tonnx\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "from gpu.utils import to_GiB, return_pruning_params, DummyDataset, Calibrator\n",
    "from pytorch_lightning.callbacks import ModelPruning\n",
    "from torch.nn.utils.prune import is_pruned\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blue/miniconda3/envs/gpu/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/blue/miniconda3/envs/gpu/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = OffsetNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonnx.export(model, torch.randn(1, 2, 3, 256, 256),  \"broncho.onnx\", verbose=True, opset_version=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(EXPLICIT_BATCH)\n",
    "config = builder.create_builder_config()\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"broncho.onnx\", \"rb\") as model:\n",
    "    ok = parser.parse(model.read())\n",
    "\n",
    "config.max_workspace_size = to_GiB(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = builder.build_serialized_network(network, config)\n",
    "with open(\"broncho.trt\", \"wb\") as f:\n",
    "    f.write(plan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INT8 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, network = configure_quantization_and_inputs(config, network, fp16=True, int8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int8_calib_set = DummyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.int8_calibrator = Calibrator(\n",
    "    int8_calib_set, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = builder.build_serialized_network(network, config)\n",
    "with open(\"broncho_int8.trt\", \"wb\") as f:\n",
    "    f.write(plan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = ModelPruning(\n",
    "        pruning_fn=\"ln_structured\",\n",
    "        parameters_to_prune=return_pruning_params(model),\n",
    "        amount=0.3,\n",
    "        use_global_unstructured=False,\n",
    "        pruning_norm=1,\n",
    "        pruning_dim=0,\n",
    "        parameter_names=['weight'],\n",
    "        use_lottery_ticket_hypothesis=False,\n",
    "        prune_on_train_epoch_end=True,\n",
    "        make_pruning_permanent=True,\n",
    "        verbose=1\n",
    "    )\n",
    "pruner.apply_pruning(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner.apply_pruning(0.3)\n",
    "print(\"Pruning has been applied as pre-hooks. The network appear as pruned -> Pruned?\", is_pruned(model))\n",
    "pruner.make_pruning_permanent(model)\n",
    "print(\"Now prune hooks are deleted, then the network appears as unpruned -> Pruned?\", is_pruned(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "525c3b681a486f141c24339ea5054bfad4b7fdf2f6d56f0ceb9811dd47c064fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
